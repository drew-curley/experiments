import os
from pathlib import Path
import torch
import pandas as pd
from transformers import AutoModelForSeq2SeqLM, AutoTokenizer
from datasets import Dataset
import sacrebleu
import logging
from torch.utils.data import DataLoader

#######################
print(f"PyTorch version: {torch.__version__}")
print(f"CUDA available: {torch.cuda.is_available()}")
print(f"CUDA version: {torch.version.cuda}")
print(f"Number of GPUs: {torch.cuda.device_count()}")
if torch.cuda.is_available():
    print(f"GPU Name: {torch.cuda.get_device_name(0)}")
#########################

# Setup logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def load_and_tokenize(tokenizer, file_path, src_col, tgt_col, max_length=128, batch_size=4):
    # Load bitext CSV
    try:
        df = pd.read_csv(file_path)
        logger.info(f"Loaded CSV with columns: {list(df.columns)}")
    except Exception as e:
        logger.error(f"Failed to load CSV {file_path}: {str(e)}")
        return None

    # Validate column indices
    if src_col >= len(df.columns) or tgt_col >= len(df.columns):
        logger.error(f"Invalid column indices: src_col={src_col}, tgt_col={tgt_col}, but CSV has {len(df.columns)} columns")
        return None

    # Rename columns
    df = df.rename(columns={df.columns[src_col]: 'source', df.columns[tgt_col]: 'target'})

    # Convert to strings and handle missing values
    df['source'] = df['source'].astype(str).fillna('')
    df['target'] = df['target'].astype(str).fillna('')

    # Log sample data
    logger.info(f"Sample source data: {df['source'].head().tolist()}")
    logger.info(f"Sample target data: {df['target'].head().tolist()}")

    dataset = Dataset.from_pandas(df)

    def tokenize_batch(examples):
        source_texts = [str(text) for text in examples['source'] if str(text).strip()]
        target_texts = [str(text) for text in examples['target'] if str(text).strip()]
        
        if not source_texts or not target_texts:
            logger.warning("Empty batch after filtering, skipping")
            return {'input_ids': [], 'attention_mask': [], 'labels': []}

        logger.debug(f"Tokenizing source: {source_texts[:2]}")
        logger.debug(f"Tokenizing target: {target_texts[:2]}")

        inputs = tokenizer(source_texts, padding='max_length',
                          truncation=True, max_length=max_length, return_tensors='pt')
        labels = tokenizer(target_texts, padding='max_length',
                          truncation=True, max_length=max_length, return_tensors='pt')
        labels['input_ids'] = [
            [(tok if tok != tokenizer.pad_token_id else -100) for tok in label]
            for label in labels['input_ids']
        ]
        return {
            'input_ids': inputs['input_ids'],
            'attention_mask': inputs['attention_mask'],
            'labels': labels['input_ids']
        }

    tokenized_dataset = dataset.map(tokenize_batch, batched=True, remove_columns=dataset.column_names)
    tokenized_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])
    return DataLoader(tokenized_dataset, batch_size=batch_size, shuffle=True)

def evaluate_and_save(model, tokenizer, eval_file, src_col, ref_col, output_path, device):
    # Load evaluation bitext
    try:
        df = pd.read_csv(eval_file)
        logger.info(f"Loaded evaluation CSV with columns: {list(df.columns)}")
    except Exception as e:
        logger.error(f"Failed to load evaluation CSV {eval_file}: {str(e)}")
        return

    # Validate column indices
    if src_col >= len(df.columns) or ref_col >= len(df.columns):
        logger.error(f"Invalid column indices: src_col={src_col}, ref_col={ref_col}, but CSV has {len(df.columns)} columns")
        return

    generated_texts = []
    bleu_scores = []
    model.eval()

    for _, row in df.iterrows():
        input_text = str(row.iloc[src_col]) if pd.notnull(row.iloc[src_col]) else ''
        if not input_text.strip():
            logger.warning(f"Skipping empty input at row {row.name}")
            generated_texts.append('')
            bleu_scores.append(0.0)
            continue

        logger.debug(f"Evaluating input: {input_text}")
        inputs = tokenizer(input_text, return_tensors='pt',
                          padding=True, truncation=True, max_length=128)
        inputs = {k: v.to(device) for k, v in inputs.items()}
        with torch.no_grad():
            out = model.generate(**inputs, max_length=128)
        gen = tokenizer.decode(out[0], skip_special_tokens=True)
        ref = str(row.iloc[ref_col]) if pd.notnull(row.iloc[ref_col]) else ''
        
        bleu = sacrebleu.sentence_bleu(gen, [ref]).score if ref.strip() else 0.0

        generated_texts.append(gen)
        bleu_scores.append(bleu)
        logger.info(f"Source: {input_text}\nGen: {gen}\nRef: {ref}\nBLEU: {bleu:.2f}\n---")

    # Append new columns and save
    df['generated_zrl'] = generated_texts
    df['bleu_score'] = bleu_scores
    try:
        df.to_csv(output_path, index=False)
        logger.info(f"Saved evaluation results to {output_path}")
    except Exception as e:
        logger.error(f"Failed to save evaluation results: {str(e)}")

def main():
    # Check versions
    try:
        import transformers
        import safetensors
        logger.info(f"Transformers version: {transformers.__version__}")
        logger.info(f"Torch version: {torch.__version__}")
        logger.info(f"Safetensors version: {safetensors.__version__}")
    except ImportError as e:
        logger.error(f"Library not found: {str(e)}. Install using: pip install transformers torch safetensors")
        return

    # Paths and filenames
    data_dir = Path(".")
    train_file = Path(r"C:\Users\dcurl\OneDrive\Desktop\experiments\input_text.csv")
    eval_file = Path(r"C:\Users\dcurl\OneDrive\Desktop\experiments\eval_text.csv")
    output_dir = Path(r"C:\Users\dcurl\OneDrive\Desktop\experiments\output")
    output_dir.mkdir(exist_ok=True)

    # Model and tokenizer
    model_name = "facebook/nllb-200-3.3B"
    try:
        logger.info(f"Loading tokenizer for {model_name}")
        tokenizer = AutoTokenizer.from_pretrained(model_name, use_safetensors=True)
        if "[zrl]" not in tokenizer.get_vocab():
            tokenizer.add_tokens(["[zrl]"])
        logger.info(f"Loading model for {model_name}")
        # Explicitly avoid meta device by loading directly to CPU or CUDA
        model = AutoModelForSeq2SeqLM.from_pretrained(model_name, use_safetensors=True, device_map=None)
        model.resize_token_embeddings(len(tokenizer))
        model.config.forced_bos_token_id = tokenizer.convert_tokens_to_ids("[zrl]")
    except Exception as e:
        logger.error(f"Failed to load model or tokenizer: {str(e)}")
        return

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    logger.info(f"Using device: {device}")

    # Check if model is on meta device and move it properly
    if any(param.device.type == 'meta' for param in model.parameters()):
        logger.info("Model detected on meta device, moving to target device with to_empty")
        model = model.to_empty(device=device)
        # Initialize parameters after moving from meta device
        model.apply(lambda m: m.reset_parameters() if hasattr(m, 'reset_parameters') else None)
    else:
        logger.info("Model not on meta device, moving to target device")
        model.to(device)

    # Verify model device
    logger.info(f"Model parameters device: {next(model.parameters()).device}")

    # Prepare dataset
    train_dataloader = load_and_tokenize(
        tokenizer, train_file, src_col=4, tgt_col=5, batch_size=4)
    if train_dataloader is None:
        logger.error("Failed to create training dataloader")
        return

    # Training setup
    optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5, weight_decay=0.01)
    num_epochs = 3
    logging_steps = 50
    total_steps = len(train_dataloader) * num_epochs
    step = 0

    # Training loop
    logger.info("Starting fine-tuning...")
    model.train()
    for epoch in range(num_epochs):
        for batch in train_dataloader:
            inputs = {k: v.to(device) for k, v in batch.items() if k != 'labels'}
            labels = batch['labels'].to(device)
            outputs = model(**inputs, labels=labels)
            loss = outputs.loss
            loss.backward()
            optimizer.step()
            optimizer.zero_grad()

            step += 1
            if step % logging_steps == 0:
                logger.info(f"Epoch {epoch+1}/{num_epochs}, Step {step}/{total_steps}, Loss: {loss.item():.4f}")

    # Save model
    try:
        model.save_pretrained(output_dir / "fine_tuned_model")
        tokenizer.save_pretrained(output_dir / "fine_tuned_model")
        logger.info(f"Model saved to {output_dir / 'fine_tuned_model'}")
    except Exception as e:
        logger.error(f"Failed to save model: {str(e)}")

    # Evaluate and save
    output_eval = output_dir / "eval_results.csv"
    evaluate_and_save(
        model, tokenizer, eval_file,
        src_col=4, ref_col=5,
        output_path=output_eval,
        device=device
    )

if __name__ == "__main__":
    main()
